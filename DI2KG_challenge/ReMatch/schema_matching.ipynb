{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCHEMA ALIGNMENT: REMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) PRE-PROCESSING AND READING OF SOURCE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' This function takes as input the folder where the sources are located and returns \n",
    "a dictionary where for each table it stores all the fields and 2 values for each'''\n",
    "def collect_attributes(base_path):\n",
    "    sources_attributes = defaultdict(lambda: defaultdict(list))\n",
    "\n",
    "    # Scroll to each folder (source) in the base folder\n",
    "    for source in os.listdir(base_path):\n",
    "        source_path = os.path.join(base_path, source)\n",
    "        \n",
    "        # Check if is a folder\n",
    "        if os.path.isdir(source_path):\n",
    "            # for each folder in sources directory\n",
    "            for file_name in os.listdir(source_path):\n",
    "                file_path = os.path.join(source_path, file_name)\n",
    "                \n",
    "                # Check if is a json file\n",
    "                if os.path.isfile(file_path) and file_name.endswith('.json'):\n",
    "                    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "                        try:\n",
    "                            record = json.load(file)\n",
    "                            for key, value in record.items():\n",
    "                                # Add for each attribute 2 example values\n",
    "                                if len(sources_attributes[source][key]) < 2:\n",
    "                                    sources_attributes[source][key].append(value)\n",
    "                        except json.JSONDecodeError:\n",
    "                            print(f\"Errore nel decodificare il file: {file_path}\")\n",
    "\n",
    "    return sources_attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test collect_attributes function\n",
    "base_path = './sources'\n",
    "\n",
    "attributes_per_source = collect_attributes(base_path)\n",
    "\n",
    "for source, attributes in attributes_per_source.items():\n",
    "    print(f\"Sorgente: {source}\")\n",
    "    print(\"Attributi trovati:\")\n",
    "    for attribute in attributes:\n",
    "        print(f\"  - {attribute}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_per_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attributes_per_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' function to save the attribute dictionary to a json file '''\n",
    "def save_attributes_to_json(attributes, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(attributes, file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_attributes_to_json(attributes_per_source, \"attributes_per_source.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) GENERATION OF SOURCE TABLE ATTRIBUTE DESCRIPTIONS VIA LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(attributes_per_source)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! export GROQ_API_KEY=\"your_key\"\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(attributes_per_source[\"ca.pcpartpicker.com\"][\"<page title>\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This part makes calls to an LLM (model Llama3) via Groq to generate a description of up to\n",
    "7 words for each field\n",
    "'''\n",
    "response_dict = defaultdict(dict)\n",
    "for source, attributes in attributes_per_source.items():\n",
    "    print(source)\n",
    "    for attribute, values in attributes.items():\n",
    "        values_string = str(values)\n",
    "        \n",
    "        # Template \n",
    "        template = \"\"\"You are an assistant who must help me to analyze the fields of a table concerning monitor characteristics.\n",
    "            Based only on the values of the field, you have to give us a description in natural language of up to 7 words for this field.\n",
    "            All I want to output is ONLY the description of the field.\n",
    "            You have to return only the description without any messages.\n",
    "            If field is empty, not return the description for this field\n",
    "            Do what I said on this field with few values and the name of the field: Name: {name}, Values: {values}\n",
    "            \"\"\"\n",
    "    \n",
    "        # Create the prompt from the template\n",
    "        prompt = ChatPromptTemplate.from_messages([(\"human\", template)])\n",
    "        chain = prompt | chat\n",
    "        response = chain.invoke({\"name\": attribute, \"values\": values_string})\n",
    "        response_dict[source][attribute] = response.content\n",
    "    \n",
    "    with open(\"attribute_description_2.json\", 'r', encoding='utf-8') as file:\n",
    "        data = json.load(file)\n",
    "\n",
    "    new_element_key = source\n",
    "    new_element_value = response_dict[source]\n",
    "\n",
    "    data[new_element_key] = new_element_value\n",
    "    # Save the updated dictionary in the JSON file\n",
    "    with open(\"attribute_description_2.json\", 'w', encoding='utf-8') as file:\n",
    "        json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"attributes_description_mediated_schema.json\", 'r', encoding='utf-8') as file:\n",
    "        mediated_schema = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediated_schema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) EMBEDDINGS ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"attributes_description.json\", 'r', encoding='utf-8') as file:\n",
    "        table_attributes_description = json.load(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embeddings model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes a string and returns the associated vector calculated by the model\n",
    "'''\n",
    "def embed_sentence(sentence):\n",
    "        # Embedding of the sentence\n",
    "        inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "        return embeddings.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jsonfile_with_embeddings(file_path, table_attributes_description):\n",
    "\n",
    "    os.makedirs(file_path, exist_ok=True)\n",
    "    for table, attributes in table_attributes_description.items():\n",
    "        for attribute, description in attributes.items():\n",
    "            # For each attribute our related json file will have these fields\n",
    "            jsonObject = {\n",
    "                \"table\": table,\n",
    "                \"nameAttribute\": attribute,\n",
    "                \"descriptionAttribute\": description\n",
    "            }\n",
    "            \n",
    "            \n",
    "            attribute_description_string = f\"{attribute} {description}\"\n",
    "\n",
    "            # Embedding attribute\n",
    "            attribute_embedding = embed_sentence(attribute_description_string)\n",
    "            attribute_embedding_list = attribute_embedding.tolist()\n",
    "            jsonObject[\"embeddingAttribute\"] = attribute_embedding_list\n",
    "\n",
    "            # Generate the json file\n",
    "            if len(attribute) > 20:\n",
    "                attribute = attribute[:15]\n",
    "            \n",
    "            file_name = f\"{table}_{attribute}.json\"\n",
    "            file_name = file_name.replace(\" \", \"_\")\n",
    "            file_name = file_name.replace(\"/\", \"_\")\n",
    "            file_name = file_name.replace(\"<\", \"\")\n",
    "            file_name = file_name.replace(\">\", \"\")\n",
    "            file_name = file_name.replace(\"-\", \"_\")\n",
    "            full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "            \n",
    "\n",
    "            # Save jsonObject to a json file\n",
    "            with open(full_path, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump(jsonObject, json_file, ensure_ascii=False, indent=4)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For attributes of sorces\n",
    "file_path = \"./attributes_documents\"\n",
    "generate_jsonfile_with_embeddings(file_path, table_attributes_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For attributes of mediated_schema\n",
    "file_path = \"./attributes_target_documents\"\n",
    "generate_jsonfile_with_embeddings(file_path, mediated_schema)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) RANK TOP j MEDIATED_SCHEMA ATTRIBUTES FOR EACH SOURCES ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Cosine Similarity function'''\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This function takes as input: a sources attribute in json format, an integer j, a threshold and \n",
    "the path to the folder where the json files relating to the mediated_schema attributes are located.\n",
    "It returns the name, description and similarity value of (at most) j documents (attributes) most \n",
    "similar to the input sources attribute whose similarity is greater than the threshold\n",
    "'''\n",
    "def rank_top_j_attributes(attribute_document_json, j, threshold_similarity, mediated_schema_dir):\n",
    "    \n",
    "    embedding_value = attribute_document_json[\"embeddingAttribute\"]\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for filename in os.listdir(mediated_schema_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(mediated_schema_dir, filename)\n",
    "            with open(file_path) as file:\n",
    "                target_attribute_document = json.load(file)\n",
    "            target_embedding_value = target_attribute_document[\"embeddingAttribute\"]\n",
    "            similarity = cosine_similarity(embedding_value, target_embedding_value)\n",
    "            if similarity > threshold_similarity:\n",
    "                similarities.append((similarity, target_attribute_document[\"nameAttribute\"], target_attribute_document[\"descriptionAttribute\"]))\n",
    "    \n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_k_similarities = similarities[:j]\n",
    "\n",
    "    return [(name, description, similarity) for similarity, name, description in top_k_similarities]  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) FINAL SCHEMA-MATCHING WITH LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! export GROQ_API_KEY=\"your_key\"\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes as input: the path to the folder where the json files relating to \n",
    "the mediated_schema attributes are located, the path to the folder where the json files\n",
    "relating to the sources attributes are located, an integer j and a threshold.\n",
    "For each source attribute, it calls the rank_top_j_attributes function and for each\n",
    "source table, it invokes the llm to choose the best matching of the top j.\n",
    "It the function returns a dictionary of dictionaries where for each attribute of each\n",
    "source table there is an associated mediated_schema field with which it matches or \n",
    "'no matching' if it does not match any mediated_schema field\n",
    "'''\n",
    "def re_match(mediated_schema_dir, attributes_documents_dir, j, threshold_similarity):\n",
    "\n",
    "    attribute_top_k_similar = defaultdict(dict)\n",
    "\n",
    "    for filename in os.listdir(attributes_documents_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(attributes_documents_dir, filename)\n",
    "            with open(file_path) as file:\n",
    "                attribute_document_json = json.load(file)\n",
    "\n",
    "            table = attribute_document_json[\"table\"]\n",
    "            name = attribute_document_json[\"nameAttribute\"]\n",
    "            attribute_top_k_similar[table][name] = rank_top_j_attributes(attribute_document_json, j, threshold_similarity, mediated_schema_dir)\n",
    "    \n",
    "    attribute_matching_result = defaultdict(dict)\n",
    "    for table, attributes_dict in attribute_top_k_similar.items():\n",
    "        print(table)\n",
    "        for attribute, most_similar_attributes in attributes_dict.items():\n",
    "                \n",
    "            most_similar_attributes_string = str(most_similar_attributes)\n",
    "            # Template \n",
    "            template = \"\"\"I have a source table and a target table. For each field in the source table, you will be provided with up \n",
    "                    to 3 plausible fields from the target table that it could match with. \n",
    "                    \n",
    "                    Each plausible field will be presented as a tuple containing (attribute name, attribute description, similarity score with the source field).\n",
    "                    \n",
    "                    Your task is to determine the best matching field from the target table for the given source field. \n",
    "                    If there is a match, respond with the attribute name of the matching field. If none of the plausible fields match, or if the list of plausible \n",
    "                    fields is empty, respond with \"no matching\".\n",
    "                    \n",
    "                    Input format:\n",
    "                        - Source field: \"source_field_name\"\n",
    "                        - Plausible target fields: [(attribute_name_1, attribute_description_1, similarity_score_1), (attribute_name_2, attribute_description_2, similarity_score_2), (attribute_name_3, attribute_description_3, similarity_score_3)]\n",
    "                    \n",
    "                    Output format:\n",
    "                        - If there is a match: \"attribute_name\"\n",
    "                        - If there is no match: \"no matching\"\n",
    "                    \n",
    "                    Example:\n",
    "                        - Source field: \"customer_id\"\n",
    "                        - Plausible target fields: [(\"user_id\", \"ID of the user\", 0.95), (\"client_id\", \"ID of the client\", 0.90), (\"order_id\", \"ID of the order\", 0.50)]\n",
    "                    Expected output:\n",
    "                        \"user_id\"\n",
    "\n",
    "                    Another example:\n",
    "                        - Source field: \"order_date\"\n",
    "                        - Plausible target fields: []\n",
    "                    Expected output:\n",
    "                        \"no matching\"\n",
    "\n",
    "                    **IMPORTANT**: The output must be ONLY the name of one target field in the Plausible target fields. DO NOT INCLUDE ANY ADDITIONAL TEXT, EXPLANATIONS, OR REASONING. Respond with only the attribute name or \"no matching\".\n",
    "                    \n",
    "                    Now, here is the source field and the plausible target fields for you to evaluate:\n",
    "                    Source field: \"{attribute}\" Plausible target fields: {most_similar_attributes}\n",
    "\n",
    "                \n",
    "            \"\"\"\n",
    "            \n",
    "            # Create prompt for the llm using the template\n",
    "            prompt = ChatPromptTemplate.from_messages([(\"human\", template)])\n",
    "            chain = prompt | chat\n",
    "            response = chain.invoke({\"attribute\": attribute, \"most_similar_attributes\": most_similar_attributes_string})\n",
    "            attribute_matching_result[table][attribute] = response.content\n",
    "        \n",
    "        with open(\"final_schema_matching.json\", 'r', encoding='utf-8') as file:\n",
    "            data = json.load(file)\n",
    "\n",
    "        new_element_key = table\n",
    "        new_element_value = attribute_matching_result[table]\n",
    "\n",
    "        data[new_element_key] = new_element_value\n",
    "        # Save the updated dictionary in the JSON file\n",
    "        with open(\"final_schema_matching.json\", 'w', encoding='utf-8') as file:\n",
    "            json.dump(data, file, ensure_ascii=False, indent=4)\n",
    "        \n",
    "        \n",
    "    return attribute_matching_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediated_schema_dir = \"./attributes_target_documents\"\n",
    "attributes_documents_dir = \"./attributes_documents\"\n",
    "j = 3\n",
    "threshold_similarity = 0.5\n",
    "result = re_match(mediated_schema_dir, attributes_documents_dir, j, threshold_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
