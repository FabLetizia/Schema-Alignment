{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SCHEMA ALIGNMENT: REMATCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (1) PRE-PROCESSING AND READING OF SOURCE DATASETS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "A function that takes as input the path to a directory containing several csv files and an integer 'v'\n",
    "and returns a dictionary of dictionaries that stores each field and 'v' sample values for each table\n",
    "'''\n",
    "def read_tables_from_folder(folder, v):\n",
    "    data = {}\n",
    "    file_list = os.listdir(folder)\n",
    "    \n",
    "    for file in file_list:\n",
    "        if file.endswith(\".csv\"):\n",
    "            table_name = os.path.splitext(file)[0]\n",
    "            file_path = os.path.join(folder, file)\n",
    "            \n",
    "            # Read the CSV file using pandas\n",
    "            try:\n",
    "                df = pd.read_csv(file_path)\n",
    "            except pd.errors.EmptyDataError:\n",
    "                print(f\"Error: File '{file}' is empty.\")\n",
    "                continue\n",
    "            \n",
    "            # Extract attributes and 3 non-NaN values for each attribute\n",
    "            attributes = {}\n",
    "            for column in df.columns:\n",
    "                # Skip NaN values and take the first 3 non-NaN values\n",
    "                sample_values = df[column].dropna().head(v).tolist()\n",
    "                attributes[column] = sample_values\n",
    "            \n",
    "            # Add to the main dictionary\n",
    "            data[table_name] = attributes\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_with_csv = \"./sources\"\n",
    "result = read_tables_from_folder(folder_with_csv, 3)\n",
    "\n",
    "# Print the result\n",
    "for table, attributes in result.items():\n",
    "    print(f\"Table: {table}\")\n",
    "    for attribute, values in attributes.items():\n",
    "        print(f\"  Attribute: {attribute}\")\n",
    "        print(f\"    Sample values: {values}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function stores a dictionary on a json file:\n",
    "store the dictionary returned by the read_tables_from_folder function \n",
    "'''\n",
    "def save_attributes_to_json(attributes, output_file):\n",
    "    # Writes the attribute dictionary to a JSON file\n",
    "    with open(output_file, 'w', encoding='utf-8') as file:\n",
    "        json.dump(attributes, file, ensure_ascii=False, indent=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_attributes_to_json(result, \"attributes_per_source.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2) GENERATION OF SOURCE TABLE ATTRIBUTE DESCRIPTIONS VIA LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_groq import ChatGroq\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! export GROQ_API_KEY=\"your_key\"\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function asks llm on the basis of the name and a few example values of each attribute to\n",
    "generate a short description\n",
    "'''\n",
    "def generate_descriptions():\n",
    "    response_dict = {}\n",
    "    for source, attributes in result.items():\n",
    "        attributes_string = str(attributes)\n",
    "        # Template \n",
    "        template = \"\"\"You are an assistant who must help me to analyse the fields of a table.\n",
    "            Here are the fields of the table each with 3 example values: {table}\n",
    "            Based only on the values of each field, you have to give us a description in natural language of up to 7 words for each field. \n",
    "            All I want to output is a list of tuples Python like this:\n",
    "            [(field title1,description1),\n",
    "            (field title2,description2)]. \n",
    "            You have to return only the list of tuples without any messages.\n",
    "            If one field is empty, not return the description for this field\"\"\"\n",
    "        \n",
    "        # Create prompt for the llm using the template\n",
    "        prompt = ChatPromptTemplate.from_messages([(\"human\", template)])\n",
    "        chain = prompt | chat\n",
    "        response = chain.invoke({\"table\": attributes_string})\n",
    "        response_dict[source] = response.content\n",
    "    return response_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributes_descriptions = generate_descriptions()\n",
    "print(attributes_descriptions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the dictionary returned by the generate_descriptions function in a json file\n",
    "save_attributes_to_json(attributes_descriptions, \"attributes_description.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (3) EMBEDDINGS ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the json file into a dictionary\n",
    "table_attributes_description = {}\n",
    "with open(\"attributes_description.json\", 'r', encoding='utf-8') as file:\n",
    "        table_attributes_description = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dict of dicts with all the attributes associated with each table with the relative description\n",
    "for table in table_attributes_description.keys():\n",
    "    tuples_list = ast.literal_eval(table_attributes_description[table])\n",
    "    table_attributes_description[table] = tuples_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_attributes_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the embeddings model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")\n",
    "model = AutoModel.from_pretrained(\"sentence-transformers/paraphrase-MiniLM-L6-v2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes a string and returns the associated vector calculated by the model\n",
    "'''\n",
    "def embed_sentence(sentence):\n",
    "        # Embedding of the sentence\n",
    "        inputs = tokenizer(sentence, return_tensors='pt', truncation=True, padding=True, max_length=128)\n",
    "        with torch.no_grad():\n",
    "            embeddings = model(**inputs).last_hidden_state.mean(dim=1)\n",
    "        return embeddings.squeeze().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_jsonfile_with_embeddings(file_path, table_attributes_description):\n",
    "\n",
    "    os.makedirs(file_path, exist_ok=True)\n",
    "    for table, attributes in table_attributes_description.items():\n",
    "        for (attribute, description) in attributes:\n",
    "            # For each attribute our related json file will have these fields\n",
    "            jsonObject = {\n",
    "                \"table\": table,\n",
    "                \"nameAttribute\": attribute,\n",
    "                \"descriptionAttribute\": description\n",
    "            }\n",
    "            \n",
    "            attribute_description_string = f\"{attribute} {description}\"\n",
    "\n",
    "            # Embedding attribute\n",
    "            attribute_embedding = embed_sentence(attribute_description_string)\n",
    "            attribute_embedding_list = attribute_embedding.tolist()\n",
    "            jsonObject[\"embeddingAttribute\"] = attribute_embedding_list\n",
    "\n",
    "            # Generate the json file\n",
    "            file_name = f\"{table}_{attribute}.json\"\n",
    "            file_name = file_name.replace(\" \", \"_\")\n",
    "            file_name = file_name.replace(\"/\", \"_\")\n",
    "            full_path = os.path.join(file_path, file_name)\n",
    "\n",
    "            # Save jsonObject to a json file\n",
    "            with open(full_path, 'w', encoding='utf-8') as json_file:\n",
    "                json.dump(jsonObject, json_file, ensure_ascii=False, indent=4)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For attributes of sorces\n",
    "target_attributes_description= {\n",
    "    \"mediated_schema\": table_attributes_description[\"mediated_schema\"]\n",
    "}\n",
    "del table_attributes_description[\"mediated_schema\"]\n",
    "file_path = \"./attributes_documents\"\n",
    "generate_jsonfile_with_embeddings(file_path, table_attributes_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For attributes of mediated_schema\n",
    "file_path = \"./attributes_target_documents\"\n",
    "generate_jsonfile_with_embeddings(file_path, target_attributes_description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (4) RANK TOP j MEDIATED_SCHEMA ATTRIBUTES FOR EACH SOURCES ATTRIBUTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import numpy as np\n",
    "from numpy.linalg import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Cosine Similarity function'''\n",
    "def cosine_similarity(vec1, vec2):\n",
    "    return np.dot(vec1, vec2) / (norm(vec1) * norm(vec2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''' \n",
    "This function takes as input: a sources attribute in json format, an integer j, a threshold and \n",
    "the path to the folder where the json files relating to the mediated_schema attributes are located.\n",
    "It returns the name, description and similarity value of (at most) j documents (attributes) most \n",
    "similar to the input sources attribute whose similarity is greater than the threshold\n",
    "'''\n",
    "def rank_top_j_attributes(attribute_document_json, j, threshold_similarity, mediated_schema_dir):\n",
    "    \n",
    "    embedding_value = attribute_document_json[\"embeddingAttribute\"]\n",
    "\n",
    "    similarities = []\n",
    "\n",
    "    for filename in os.listdir(mediated_schema_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(mediated_schema_dir, filename)\n",
    "            with open(file_path) as file:\n",
    "                target_attribute_document = json.load(file)\n",
    "            target_embedding_value = target_attribute_document[\"embeddingAttribute\"]\n",
    "            similarity = cosine_similarity(embedding_value, target_embedding_value)\n",
    "            if similarity > threshold_similarity:\n",
    "                similarities.append((similarity, target_attribute_document[\"nameAttribute\"], target_attribute_document[\"descriptionAttribute\"]))\n",
    "    \n",
    "    similarities.sort(reverse=True, key=lambda x: x[0])\n",
    "    top_k_similarities = similarities[:j]\n",
    "\n",
    "    return [(name, description, similarity) for similarity, name, description in top_k_similarities]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (5) FINAL SCHEMA-MATCHING WITH LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !! export GROQ_API_KEY=\"your_key\"\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "chat = ChatGroq(temperature=0, groq_api_key=api_key, model_name=\"llama3-8b-8192\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "This function takes as input: the path to the folder where the json files relating to \n",
    "the mediated_schema attributes are located, the path to the folder where the json files\n",
    "relating to the sources attributes are located, an integer j and a threshold.\n",
    "For each source attribute, it calls the rank_top_j_attributes function and for each\n",
    "source table, it invokes the llm to choose the best matching of the top j.\n",
    "It the function returns a dictionary of dictionaries where for each attribute of each\n",
    "source table there is an associated mediated_schema field with which it matches or \n",
    "'no matching' if it does not match any mediated_schema field\n",
    "'''\n",
    "def re_match(mediated_schema_dir, attributes_documents_dir, j, threshold_similarity):\n",
    "\n",
    "    attribute_top_k_similar = defaultdict(dict)\n",
    "\n",
    "    for filename in os.listdir(attributes_documents_dir):\n",
    "        if filename.endswith(\".json\"):\n",
    "            file_path = os.path.join(attributes_documents_dir, filename)\n",
    "            with open(file_path) as file:\n",
    "                attribute_document_json = json.load(file)\n",
    "\n",
    "            table = attribute_document_json[\"table\"]\n",
    "            name = attribute_document_json[\"nameAttribute\"]\n",
    "            attribute_top_k_similar[table][name] = rank_top_j_attributes(attribute_document_json, j, threshold_similarity, mediated_schema_dir)\n",
    "    \n",
    "    attribute_matching_result = {}\n",
    "    for table, attributes_dict in attribute_top_k_similar.items():\n",
    "        attributes_string = str(attributes_dict)\n",
    "        # Template \n",
    "        template = \"\"\"You are an assistant who has to help us with a fields matching problem. Below is a table with all its \n",
    "            associated fields and the best fields of the target table on which it can do matching with a description and \n",
    "            the similarity values between the fields:\n",
    "            {table}\n",
    "            Using this information tell me for each field in the table: whether or not the field matches one of the proposed \n",
    "            fields and if so which one. \n",
    "            (Many fields do not have a matching in the target schema, so in that case you have to tell me that \n",
    "            the field does not have a target field with which it matches).\n",
    "            You must return the final result in only the following way\n",
    "            [\n",
    "            field_name1: field_name_target_matching\n",
    "            field_name2: no matching\n",
    "            field_name3: field_name_target_matching\n",
    "            field_name4: no matching\n",
    "            ...\n",
    "            ]\n",
    "\n",
    "            An example:\n",
    "            [\n",
    "            name: name\n",
    "            id: no matching\n",
    "            birthday year: no matching\n",
    "            address: location\n",
    "            ...\n",
    "            ]\n",
    "        \"\"\"\n",
    "        \n",
    "        # Create prompt for the llm using the template\n",
    "        prompt = ChatPromptTemplate.from_messages([(\"human\", template)])\n",
    "        chain = prompt | chat\n",
    "        response = chain.invoke({\"table\": attributes_string})\n",
    "        attribute_matching_result[table] = response.content\n",
    "        \n",
    "    return attribute_matching_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mediated_schema_dir = \"./attributes_target_documents\"\n",
    "attributes_documents_dir = \"./attributes_documents\"\n",
    "j = 3\n",
    "threshold_similarity = 0.5\n",
    "result = re_match(mediated_schema_dir, attributes_documents_dir, j, threshold_similarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final result in a json file\n",
    "save_attributes_to_json(result, \"final_schema_matching.json\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
